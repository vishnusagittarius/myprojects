{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hello and welcome to this fun lecture, detecting faces on images\n",
    "* We shall be using haar cascade classifier for this task\n",
    "* the cascade is just an XML file that contains the data to detect faces.\n",
    "* Haar cascades are commonly used to detect faces due to the fact that they are relatively fast and easy to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets import packages\n",
    "import cv2\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from snipe.snipe import sniper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "image = cv2.imread('jlo.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "scale_factor = 1.3\n",
    "minNeighbors = 5\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray,scale_factor,minNeighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function ( face_classifier) detects the actual face and it plays a major role in our code, so let’s \n",
    "    go over the options it has:\n",
    "1.\tThe detectMultiScale function is a general function that detects objects. \n",
    "    Since we are calling it on the face cascade, that’s what it detects.\n",
    "2.\tThe first option is the grayscale image.\n",
    "3.\tThe second is the scaleFactor. Since some faces may be closer to the camera, \n",
    "    they would appear bigger than the faces in the back. The scale factor compensates for this.\n",
    "4.\tThe detection algorithm uses a moving window to detect objects. \n",
    "    minNeighbors defines how many objects are detected near the current one before it declares the face found.\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Tuning Cascade Classifiers\n",
    "ourClassifier.detectMultiScale(input image, Scale Factor, Min Neighbors)\n",
    "* Scale Factor Specifies how much we reduce the image size each time we scale, E.g in face detection we typically\n",
    "use 1.3. This means we reduce the image by 30% each time its scaled.\n",
    "Smaller values like 1.05 will take longer to compute, but will increase the rate of detection\n",
    "\n",
    "* Min neighbors Specifies the number of neighbors each potential window should have in order to consider it a spositive detection.\n",
    "Typically set between 3-6. It acts as sensitivity setting, low values will sometimes detect multiple faces over a single face.\n",
    "high values will ensure less false positives, but you may miss some faces\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if faces is ():\n",
    "\tprint('No faces found')\n",
    "\n",
    "img_width, img_height = image.shape[:2]\n",
    "recorder(img_width, img_height,image,'online')\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    sniper(x,y,x+w,y+h, image, color=(90,250,200))\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live face detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section we are going to perform a live face detection\n",
    "* you can use your own webcam but I will be using a video in this scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets import packages\n",
    "import cv2\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def face_detector(img):\n",
    "\t#convert image to grayscale\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\tfaces = face_classifier.detectMultiScale(gray, 1.3,5)\n",
    "\tif faces is ():\n",
    "\t\treturn img \n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\t\n",
    "\t\trect = cv2.rectangle(img, (x,y),(x+w,y+h),(123,123,123),1)\n",
    "\t\t\n",
    "\t\tsniper(x, y, x+w, y+h, img,color=(90,250,200))\n",
    "\treturn rect\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('smiles.mp4')\n",
    "\n",
    "#We then have to define a while loop to continuosly keep taking image frames until we break it \n",
    "while True:\n",
    "\tret, frame = cap.read()\n",
    "\tcv2.imshow('Our Face Extractor', face_detector(frame))\n",
    "\tif cv2.waitKey(1) == 13: # wait for then ENTER to be pressed to exit the window\n",
    "\t\tbreak\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
