{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.layers import Dropout,Flatten,Dense,Activation\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=8\n",
    "img_width,img_height =160,160\n",
    "batch_size=32\n",
    "nb_filters1=32\n",
    "nb_filters2=64\n",
    "conv1_size=3\n",
    "conv2_size=2\n",
    "num_classes=3\n",
    "lr=0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path='/home/vishnu/my_project_dir/open cv learning/celebrities/'\n",
    "# validation_data_path='/home/vishnu/Downloads/dogs-vs-cats/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(filters=nb_filters1,kernel_size=(conv1_size,conv1_size),padding='same',input_shape=(img_width,img_height,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=nb_filters2,kernel_size=(conv2_size,conv2_size),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=250,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(lr=lr),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(train_data_path,target_size=(img_width,img_height),batch_size=batch_size,class_mode='categorical',subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator=train_datagen.flow_from_directory(train_data_path,target_size=(img_width,img_height),batch_size=batch_size,class_mode='categorical',subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_epoch=318\n",
    "validation_steps=135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.3089 - accuracy: 0.9000 - val_loss: 0.3153 - val_accuracy: 0.9884\n",
      "Epoch 2/8\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1883 - accuracy: 0.9455 - val_loss: 0.4414 - val_accuracy: 0.8593\n",
      "Epoch 3/8\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.1107 - accuracy: 0.9727 - val_loss: 0.2128 - val_accuracy: 0.9757\n",
      "Epoch 4/8\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9989\n",
      "Epoch 5/8\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.3019 - val_accuracy: 0.8317\n",
      "Epoch 6/8\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9905\n",
      "Epoch 7/8\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 8/8\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator,epochs=epochs,validation_data=test_generator,validation_steps=validation_steps,steps_per_epoch=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target_dir='/home/vishnu/my_project_dir/open cv learning/celebrities/models/'\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    os.mkdir(target_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/home/vishnu/my_project_dir/flask/models/model_politicians.h5')\n",
    "model.save_weights('/home/vishnu/my_project_dir/flask/models/weights_politicians.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width,img_height=160,160\n",
    "model_path=\"/home/vishnu/my_project_dir/flask/models/model_politicians.h5\"\n",
    "model_weights_path='/home/vishnu/my_project_dir/open cv learning/celebrities/models/weights_catdog.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(model_path)\n",
    "model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(file):\n",
    "    x=load_img(file,target_size=(img_width,img_height))\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    array=model.predict(x)\n",
    "    result=array[0]\n",
    "    answer=np.argmax(result)\n",
    "    \n",
    "    if answer==0:\n",
    "        print(\"label is Modi\")\n",
    "    elif answer==1:\n",
    "        print(\"label is Pinarayi\")\n",
    "    elif answer==1:\n",
    "        print(\"label is Trump\")\n",
    "        \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label is Modi\n"
     ]
    }
   ],
   "source": [
    "my_pred=predict(\"modi.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
